from flask import Flask, request, jsonify
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from colect import data_by_city, data_by_location, current_aqi_prov, weather_by_city, weather_by_location
from list_to_dict import list_to_dict, list_to_dict_prov, weather_list_to_dict
from convert import convert_ISPU
import pandas as pd

app = Flask(__name__)
  
# load model
model = load_model("Model/lstm_6_3_e50/my_model.h5")
model1 = load_model("Model/lstm_6_3_e50/my_model_weather.h5")

@app.route("/")
def index():
  return "Welcome to Airmonitor Forecast APIs"

# /by_city?city=Jakarta&key=8ad9eca88a2e4330a022ad816a7d9886
@app.route("/by_city")
def by_city():
  kota = request.args.get('city', default = "Jakarta", type = str)
  weatherbit_key = request.args.get('key', default = "8ad9eca88a2e4330a022ad816a7d9886", type = str)

  # collect data
  a = data_by_city(kota, weatherbit_key)
  a = a.sort_index()

  # scaling and reshape
  scaler = MinMaxScaler()
  data = scaler.fit_transform(a)
  data = data.reshape(1,6,7)

  # predictions and dataframing
  predictions = model.predict(data)
  predictions = predictions.reshape(3,7)
  predictions = scaler.inverse_transform(predictions)
  predictions = predictions.tolist()
  predictions = pd.DataFrame(predictions)
  predictions = predictions.rename(columns={0: "aqi", 1: "pm10", 2: "pm25", 
                                          3: "o3", 4: "so2", 
                                          5: "no2", 6: "co"})
  # convert to ISPU
  predictions = convert_ISPU(predictions)
  
  # merge data a and predictions
  frame = [a, predictions]
  df_merge = pd.concat(frame)
  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')
  df_merge = df_merge.sort_index(ascending=False)

  # reset index and format datetime to obj
  df_merge = df_merge.reset_index()
  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')

  # data prediction for return
  result_pred = df_merge[:3]
  result_pred = result_pred.sort_index(ascending=False)
  result_pred = result_pred.values.tolist()
  result_pred = list_to_dict(result_pred)

  # data history for return
  result_hist = df_merge[4:7]
  result_hist = result_hist.values.tolist()
  result_hist = list_to_dict(result_hist)
  a = a.sort_index()

  # merge result_pred and result_hist to dict data
  data = ({
      "data": ({
          "forecast": result_pred,
          "history": result_hist
      })
  })

   
  return data

# /by_location?lat=35&lon=-78&key=8ad9eca88a2e4330a022ad816a7d9886
@app.route("/by_location")
def by_location():
  lat = request.args.get('lat', default = 35, type = float)
  lon = request.args.get('lon', default = -78, type = float)
  weatherbit_key = request.args.get('key', default = "8ad9eca88a2e4330a022ad816a7d9886", type = str)

  # collect data
  a = data_by_location(lat, lon, weatherbit_key)
  a = a.sort_index()

  # scaling and reshape
  scaler = MinMaxScaler()
  data = scaler.fit_transform(a)
  data = data.reshape(1,6,7)

  # predictions and dataframing
  predictions = model.predict(data)
  predictions = predictions.reshape(3,7)
  predictions = scaler.inverse_transform(predictions)
  predictions = predictions.tolist()
  predictions = pd.DataFrame(predictions)
  predictions = predictions.rename(columns={0: "aqi", 1: "pm10", 2: "pm25", 
                                          3: "o3", 4: "so2", 
                                          5: "no2", 6: "co"})

  # convert to ISPU
  predictions = convert_ISPU(predictions)

  # merge data a and predictions
  frame = [a, predictions]
  df_merge = pd.concat(frame)
  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')
  df_merge = df_merge.sort_index(ascending=False)

  # reset index and format datetime to obj
  df_merge = df_merge.reset_index()
  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')

  # data prediction for return
  result_pred = df_merge[:3]
  result_pred = result_pred.sort_index(ascending=False)
  result_pred = result_pred.values.tolist()
  result_pred = list_to_dict(result_pred)

  # data history for return
  result_hist = df_merge[4:7]
  result_hist = result_hist.values.tolist()
  result_hist = list_to_dict(result_hist)
  a = a.sort_index()

  # merge result_pred and result_hist to dict data
  data = ({
      "data": ({
          "forecast": result_pred,
          "history": result_hist
      })
  })

   
  return data

# /current?key=8ad9eca88a2e4330a022ad816a7d9886
@app.route("/current")
def current():
  weatherbit_key = request.args.get('key', default = "8ad9eca88a2e4330a022ad816a7d9886", type = str)

  data = current_aqi_prov(weatherbit_key)
  data = list_to_dict_prov(data)
  
  data = ({
      "data": ({
          "current": data
      })
  })
  
  return data

# /w_by_city?city=Jakarta&key=a98a87d5120e4a86ba63d4c67fe8e81f
@app.route("/w_by_city")
def w_by_city():
  kota = request.args.get('city', default = "Jakarta", type = str)
  weatherbit_key = request.args.get('key', default = "a98a87d5120e4a86ba63d4c67fe8e81f", type = str)

  # collect data
  a = weather_by_city(kota, weatherbit_key)
  a = a.sort_index()

  # scaling and reshape
  scaler = MinMaxScaler()
  data = scaler.fit_transform(a)
  data = data.reshape(1,3,3)

  # predictions and dataframing
  predictions = model1.predict(data)
  predictions = predictions.reshape(3,3)
  predictions = scaler.inverse_transform(predictions)
  predictions = predictions.tolist()
  predictions = pd.DataFrame(predictions)
  predictions = predictions.rename(columns={0: "rh", 1: "wind_spd", 2: "temp"})

  # merge data a and predictions
  frame = [a, predictions]
  df_merge = pd.concat(frame)
  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')
  df_merge = df_merge.sort_index(ascending=False)

  # reset index and format datetime to obj
  df_merge = df_merge.reset_index()
  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')

  # data prediction for return
  result_pred = df_merge[:3]
  result_pred = result_pred.sort_index(ascending=False)
  result_pred = result_pred.values.tolist()
  result_pred = weather_list_to_dict(result_pred)

  # data history for return
  result_hist = df_merge[3:6]
  result_hist = result_hist.values.tolist()
  result_hist = weather_list_to_dict(result_hist)
  a = a.sort_index()

  # merge result_pred and result_hist to dict data
  data = ({
      "data": ({
          "forecast": result_pred,
          "history": result_hist
      })
  })
  return data
   
  

# /w_by_location?lat=35&lon=-78&key=8ad9eca88a2e4330a022ad816a7d9886
@app.route("/w_by_location")
def w_by_location():
  lat = request.args.get('lat', default = 35, type = float)
  lon = request.args.get('lon', default = -78, type = float)
  weatherbit_key = request.args.get('key', default = "8ad9eca88a2e4330a022ad816a7d9886", type = str)

  # collect data
  a = weather_by_location(lat, lon, weatherbit_key)
  a = a.sort_index()

  # scaling and reshape
  scaler = MinMaxScaler()
  data = scaler.fit_transform(a)
  data = data.reshape(1,3,3)

  # predictions and dataframing
  predictions = model1.predict(data)
  predictions = predictions.reshape(3,3)
  predictions = scaler.inverse_transform(predictions)
  predictions = predictions.tolist()
  predictions = pd.DataFrame(predictions)
  predictions = predictions.rename(columns={0: "rh", 1: "wind_spd", 2: "temp"})

  # merge data a and predictions
  frame = [a, predictions]
  df_merge = pd.concat(frame)
  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')
  df_merge = df_merge.sort_index(ascending=False)

  # reset index and format datetime to obj
  df_merge = df_merge.reset_index()
  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')

  # data prediction for return
  result_pred = df_merge[:3]
  result_pred = result_pred.sort_index(ascending=False)
  result_pred = result_pred.values.tolist()
  result_pred = weather_list_to_dict(result_pred)

  # data history for return
  result_hist = df_merge[3:6]
  result_hist = result_hist.values.tolist()
  result_hist = weather_list_to_dict(result_hist)
  a = a.sort_index()

  # merge result_pred and result_hist to dict data
  data = ({
      "data": ({
          "forecast": result_pred,
          "history": result_hist
      })
  })
  return data


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)

import requests
import json
import pandas as pd
from glom import glom
import datetime

def data_by_city(city,key):    
    # Base URL and api key
    link = "https://api.weatherbit.io/v2.0/history/airquality?"
    api_key = key

    # city variable and req to weatherbit.io
    city = f"city={city}&country=indonesia"
    history_72hour = link + city + "&key=" + api_key
    r = requests.get(history_72hour)

    # Json to Dict
    df = pd.read_json(r.text)
    target = df['data']
    spec = {
            'datetime' : (['timestamp_local']),
            'aqi' : (['aqi']),
            'pm10' : (['pm10']),
            'pm25' : (['pm25']),
            'o3' : (['o3']),
            'so2' : (['so2']),
            'no2' : (['no2']),
            'co' : (['co']),
    }

    data_json = glom(target, spec)

    # Dict to Dataframe
    df = pd.DataFrame.from_dict(data_json)
    
    # format datetime and set to index
    new = df["datetime"].str.split("T", n = 1, expand = True)
    df["date"]= new[0]
    df["time"]= new[1]
    df['datetime'] = df.date.map(str) + " " + df.time
    df = df.drop(['date', 'time'], axis=1)
    df.datetime = pd.to_datetime(df.datetime)
    df = df.set_index('datetime')
    
    # get last datetime
    df = df[:6]   

    return df

def data_by_location(lat,lon,key):    
    # Base URL and api key
    link = "https://api.weatherbit.io/v2.0/history/airquality?"
    api_key = str(key)

    # location variable and req to weatherbit.io
    lat = str(lat)
    lon = str(lon)
    lat_lon = f"lat={lat}&lon={lon}"
    history_72hour = link + lat_lon + "&key=" + api_key
    r = requests.get(history_72hour)

    # Json to Dict
    df = pd.read_json(r.text)
    target = df['data']
    spec = {
            'datetime' : (['timestamp_local']),
            'aqi' : (['aqi']),
            'pm10' : (['pm10']),
            'pm25' : (['pm25']),
            'o3' : (['o3']),
            'so2' : (['so2']),
            'no2' : (['no2']),
            'co' : (['co']),
    }

    data_json = glom(target, spec)

    # Dict to Dataframe
    df = pd.DataFrame.from_dict(data_json)
    
    # format datetime and set to index
    new = df["datetime"].str.split("T", n = 1, expand = True)
    df["date"]= new[0]
    df["time"]= new[1]
    df['datetime'] = df.date.map(str) + " " + df.time
    df = df.drop(['date', 'time'], axis=1)
    df.datetime = pd.to_datetime(df.datetime)
    df = df.set_index('datetime')
    
    # get last datetime
    df = df[:6]   
    
    return df

def current_aqi_prov(key):
  kota = {
      # serang - samarinda
      "-6.11528": "106.15417", "-6.92222": "107.60694", "-6.99306": "110.42083",
      "-7.24917": "112.7508", "-7.80139": "110.3647", "-8.65": "115.21667",
      "-8.58333": "116.11667", "-10.1708": "123.60694", "-0.03194": "109.325",
      "-3.31987": "114.5908", "-2.20833": "113.91667", "-0.49167": "117.1458",
      # tanjung selor - manokwari
      "2.8375": "117.36528", "-2.68056": "118.88611", "-3.9778": "122.51507",
      "-5.14861": "119.43194", "-0.90833": "119.87083", "1.48218": "124.84892",
      "0.5375": "123.0625 ", "-3.69583": "128.18333", "0.73729": "127.5588",
      "-2.53371": "140.71813", "-0.86291": "134.06402",
      # bengkulu - pangkal pinang
      "-3.57710": "102.36053", "-6.20856": "106.83499", "-1.61112": "103.61570",
      "0.91849": "104.46710", "0.50871": "101.45400", "-0.93492": "100.40323",
      "-2.97313": "104.77291", "3.63781": "98.70642", "-5.39714": "105.26549",
      "5.57007": "95.36970", "-2.12960": "106.10302"
  }

  z = []
  data = []

  for x,y in kota.items():
    api_key = key#"8ad9eca88a2e4330a022ad816a7d9886"
    lat = x

    current = f"https://api.weatherbit.io/v2.0/current/airquality?lat={x}&lon={y}&key={api_key}"
    r = requests.get(current)
    
    df = pd.read_json(r.text)
    target = df["data"]
    spec = {      
        "aqi" : (["aqi"]),
        "pm10" : (["pm10"]),
        "pm25" : (["pm25"]),
        "o3" : (["o3"]),
        "so2" : (["so2"]),
        "no2" : (["no2"]),
        "co" : (["co"])
    }

    data_json = glom(target, spec)
    df_aqi = pd.DataFrame.from_dict(data_json)
    df_city = df[["city_name", "lat", "lon"]]
    df_merge = pd.concat([df_city, df_aqi], axis=1, sort=False)
    df_merge = df_merge.values.tolist()
    z.append(df_merge)

    for x in z:
      for y in x:
        if y not in data:
          data.append(y)
    
  return data

def weather_by_city(city,key):    
    # Base URL and api key
    link = "https://api.weatherbit.io/v2.0/history/hourly?"
    api_key = str(key)
    today = datetime.date.today()
    start = today - datetime.timedelta(days = 1)
    end = today
    # city variable and req to weatherbit.io
    city = f"city={city}&country=indonesia"
    history_72hour = link + city + "&start_date=" + str(start) + "&end_date=" + str(end) + "&tz=local&key=" + api_key
    r = requests.get(history_72hour)
    j = r.json()
    jd = j['data']

    spec = {
            'datetime' : (['datetime']),
            'rh' : (['rh']),
            'wind_spd' : (['wind_spd']),
            'temp' : (['temp']),
    }
    data_json = glom(jd, spec)
    df = pd.DataFrame.from_dict(data_json)
    new = df["datetime"].str.split(":", n = 1, expand = True)
    df["date"]= new[0]
    df["time"]= new[1]
    df['datetime'] = df.date.map(str) + " " + df.time
    df = df.drop(['date', 'time'], axis=1)
    df.datetime = pd.to_datetime(df.datetime)
    df = df.set_index('datetime')
    
    # get last datetime
    df = df[:3]   

    return df

def weather_by_location(lat,lon,key):    
    # Base URL and api key
    link = "https://api.weatherbit.io/v2.0/history/hourly?"
    api_key = str(key)
    today = datetime.date.today()
    start = today - datetime.timedelta(days = 1)
    end = today
    # location variable and req to weatherbit.io
    lat = str(lat)
    lon = str(lon)
    lat_lon = f"lat={lat}&lon={lon}"
    history_72hour = link + lat_lon + "&start_date=" + str(start) + "&end_date=" + str(end) + "&tz=local&key=" + api_key
    r = requests.get(history_72hour)
    j = r.json()
    jd = j['data']

    spec = {
            'datetime' : (['datetime']),
            'rh' : (['rh']),
            'wind_spd' : (['wind_spd']),
            'temp' : (['temp']),
    }
    data_json = glom(jd, spec)
    df = pd.DataFrame.from_dict(data_json)
    new = df["datetime"].str.split(":", n = 1, expand = True)
    df["date"]= new[0]
    df["time"]= new[1]
    df['datetime'] = df.date.map(str) + " " + df.time
    df = df.drop(['date', 'time'], axis=1)
    df.datetime = pd.to_datetime(df.datetime)
    df = df.set_index('datetime')
    
    # get last datetime
    df = df[:3]   

    return df

#convert aqi to ispu
from glom import glom
import json
import pandas as pd
import numpy as np
from numpy import array   
    
def convert_ISPU(predictions):
  for i in range(0, len(predictions)):
    max_particle = predictions.iloc[i].max()
    q1 = predictions.pm10.iloc[i] #pm10
    q2 = predictions.pm25.iloc[i] #pm2,5
    q3 = predictions.o3.iloc[i] #o3
    q4 = predictions.so2.iloc[i] #so2
    q5 = predictions.no2.iloc[i] #no2
    q6 = predictions.co.iloc[i] #co
    if max_particle == q1: 
      if q1 > 420:
        k, t , r = (q1 - 420),(500 - 420), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 350 < q1 < 420:
        k, t , r = (q1 - 350),(420 - 350), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 150 < q1 < 350:
        k, t , r = (q1 - 150),(350 - 150), (200 - 100)
        ISPU = (r*k/t) + 100
      else :
        k, t , r = (q1 - 50),(150 - 50), (100 - 50)
        ISPU = (r*k/t) + 50
    elif max_particle == q2:
      if q2 > 250.4:
        k, t , r = (q2 - 250.4),(500 - 250.4), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 150.4 < q2 < 250.4: 
        k, t , r = (q2 - 150.4),(250.4 - 150.4), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 55.4 < q2 < 150.4:
        k, t , r = (q2 - 55.4),(150.4 - 55.4), (200 - 100)
        ISPU = (r*k/t) + 100
      else :
        k, t , r = (q2 - 15.5),(55.4 - 15.5), (100 - 50)
        ISPU = (r*k/t) + 50
    elif max_particle == q3:
      if q3 > 800:
        k, t , r = (q3 - 800),(1000 - 800), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 400 < q3 < 800: 
        k, t , r = (q3 - 400),(800 - 400), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 235 < q3 < 400:
        k, t , r = (q3 - 235),(400 - 235), (200 - 100)
        ISPU = (r*k/t) + 100
      else :
        k, t , r = (q3 - 120),(235 - 120), (100 - 50)
        ISPU = (r*k/t) + 50 
    elif max_particle == q4:
      if q4 > 800:
        k, t , r = (q4 - 800),(1200 - 800), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 400< q4 < 800: 
        k, t , r = (q4 - 400),(800 - 400), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 180 < q4 < 400:
        k, t , r = (q4 - 180),(400 - 180), (200 - 100)
        ISPU = (r*k/t) + 100
      else :
        k, t , r = (q4 - 52),(180 - 52), (100 - 50)
        ISPU = (r*k/t) + 50
    elif max_particle == q5:
      if q5 > 2260:
        k, t , r = (q5 - 2260),(3000 - 2260), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 1130 < q5 < 2260: 
        k, t , r = (q5 - 1130),(2260 - 1130), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 200 < q5 < 1130:
        k, t , r = (q5 - 200),(1130 - 200), (200 - 100)
        ISPU = (r*k/t) + 100
      else:  
        k, t , r = (q5 - 80),(235 - 80), (100 - 50)
        ISPU = (r*k/t) + 50
    else : 
      if q6 > 30000:
        k, t , r = (q6 - 30000),(45000 - 30000), (400 - 300)
        ISPU = (r*k/t) + 300
      elif 15000 < q6 < 30000: 
        k, t , r = (q6 - 15000),(30000 - 15000), (300 - 200)
        ISPU = (r*k/t) + 200
      elif 8000 < q6 < 15000:
        k, t , r = (q6 - 8000),(15000 - 8000), (200 - 100)
        ISPU = (r*k/t) + 100
      else :
        k, t , r = (q6 - 4000),(8000 - 4000), (100 - 50)
        ISPU = (r*k/t) + 50
    predictions.aqi.iloc[i] = round(ISPU)
  return predictions

from glom import glom
import json
import requests
import pandas as pd
import numpy as np
from numpy import array
        
def current_aqi_prov(key):
  kota = {
      # serang - samarinda
      "-6.11528": "106.15417", "-6.92222": "107.60694", "-6.99306": "110.42083",
      "-7.24917": "112.7508", "-7.80139": "110.3647", "-8.65": "115.21667",
      "-8.58333": "116.11667", "-10.1708": "123.60694", "-0.03194": "109.325",
      "-3.31987": "114.5908", "-2.20833": "113.91667", "-0.49167": "117.1458",
      # tanjung selor - manokwari
      "2.8375": "117.36528", "-2.68056": "118.88611", "-3.9778": "122.51507",
      "-5.14861": "119.43194", "-0.90833": "119.87083", "1.48218": "124.84892",
      "0.5375": "123.0625 ", "-3.69583": "128.18333", "0.73729": "127.5588",
      "-2.53371": "140.71813", "-0.86291": "134.06402",
      # bengkulu - pangkal pinang
      "-3.57710": "102.36053", "-6.20856": "106.83499", "-1.61112": "103.61570",
      "0.91849": "104.46710", "0.50871": "101.45400", "-0.93492": "100.40323",
      "-2.97313": "104.77291", "3.63781": "98.70642", "-5.39714": "105.26549",
      "5.57007": "95.36970", "-2.12960": "106.10302"
  }

  z = []
  data = []

  for x,y in kota.items():
    api_key = key#"8ad9eca88a2e4330a022ad816a7d9886"
    lat = x

    current = f"https://api.weatherbit.io/v2.0/current/airquality?lat={x}&lon={y}&key={api_key}"
    r = requests.get(current)
    
    df = pd.read_json(r.text)
    target = df["data"]
    spec = {      
        "aqi" : (["aqi"]),
        "pm10" : (["pm10"]),
        "pm25" : (["pm25"]),
        "o3" : (["o3"]),
        "so2" : (["so2"]),
        "no2" : (["no2"]),
        "co" : (["co"])
    }

    data_json = glom(target, spec)
    df_aqi = pd.DataFrame.from_dict(data_json)
    df_city = df[["city_name", "lat", "lon"]]
    df_merge = pd.concat([df_city, df_aqi], axis=1, sort=False)
    df_merge = df_merge.values.tolist()
    z.append(df_merge)

    for x in z:
      for y in x:
        if y not in data:
          data.append(y)
    
  return data
FROM python:3.8

COPY requirements.txt .

RUN pip install -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["flask", "run", "--host=0.0.0.0", "--port=5000"]
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f94c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.27.76:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.27.76 - - [13/Jun/2022 19:14:40] \"GET /by_city?city=jakarta&key=8ad9eca88a2e4330a022ad816a7d9886 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from colect import data_by_city, data_by_location, current_aqi_prov, weather_by_city, weather_by_location\n",
    "from list_to_dict import list_to_dict, list_to_dict_prov, weather_list_to_dict\n",
    "from convert import convert_ISPU\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "  \n",
    "# load model\n",
    "model = load_model(\"Model/lstm_6_3_e50/my_model.h5\")\n",
    "model1 = load_model(\"Model/lstm_6_3_e50/my_model_weather.h5\")\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "  return \"Welcome to Airmonitor Forecast APIs\"\n",
    "\n",
    "# /by_city?city=Jakarta&key=8ad9eca88a2e4330a022ad816a7d9886\n",
    "@app.route(\"/by_city\")\n",
    "def by_city():\n",
    "  kota = request.args.get('city', default = \"Jakarta\", type = str)\n",
    "  weatherbit_key = request.args.get('key', default = \"8ad9eca88a2e4330a022ad816a7d9886\", type = str)\n",
    "\n",
    "  # collect data\n",
    "  a = data_by_city(kota, weatherbit_key)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # scaling and reshape\n",
    "  scaler = MinMaxScaler()\n",
    "  data = scaler.fit_transform(a)\n",
    "  data = data.reshape(1,6,7)\n",
    "\n",
    "  # predictions and dataframing\n",
    "  predictions = model.predict(data)\n",
    "  predictions = predictions.reshape(3,7)\n",
    "  predictions = scaler.inverse_transform(predictions)\n",
    "  predictions = predictions.tolist()\n",
    "  predictions = pd.DataFrame(predictions)\n",
    "  predictions = predictions.rename(columns={0: \"aqi\", 1: \"pm10\", 2: \"pm25\", \n",
    "                                          3: \"o3\", 4: \"so2\", \n",
    "                                          5: \"no2\", 6: \"co\"})\n",
    "  # convert to ISPU\n",
    "  predictions = convert_ISPU(predictions)\n",
    "  \n",
    "  # merge data a and predictions\n",
    "  frame = [a, predictions]\n",
    "  df_merge = pd.concat(frame)\n",
    "  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')\n",
    "  df_merge = df_merge.sort_index(ascending=False)\n",
    "\n",
    "  # reset index and format datetime to obj\n",
    "  df_merge = df_merge.reset_index()\n",
    "  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  # data prediction for return\n",
    "  result_pred = df_merge[:3]\n",
    "  result_pred = result_pred.sort_index(ascending=False)\n",
    "  result_pred = result_pred.values.tolist()\n",
    "  result_pred = list_to_dict(result_pred)\n",
    "\n",
    "  # data history for return\n",
    "  result_hist = df_merge[4:7]\n",
    "  result_hist = result_hist.values.tolist()\n",
    "  result_hist = list_to_dict(result_hist)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # merge result_pred and result_hist to dict data\n",
    "  data = ({\n",
    "      \"data\": ({\n",
    "          \"forecast\": result_pred,\n",
    "          \"history\": result_hist\n",
    "      })\n",
    "  })\n",
    "\n",
    "   \n",
    "  return data\n",
    "\n",
    "# /by_location?lat=35&lon=-78&key=8ad9eca88a2e4330a022ad816a7d9886\n",
    "@app.route(\"/by_location\")\n",
    "def by_location():\n",
    "  lat = request.args.get('lat', default = 35, type = float)\n",
    "  lon = request.args.get('lon', default = -78, type = float)\n",
    "  weatherbit_key = request.args.get('key', default = \"8ad9eca88a2e4330a022ad816a7d9886\", type = str)\n",
    "\n",
    "  # collect data\n",
    "  a = data_by_location(lat, lon, weatherbit_key)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # scaling and reshape\n",
    "  scaler = MinMaxScaler()\n",
    "  data = scaler.fit_transform(a)\n",
    "  data = data.reshape(1,6,7)\n",
    "\n",
    "  # predictions and dataframing\n",
    "  predictions = model.predict(data)\n",
    "  predictions = predictions.reshape(3,7)\n",
    "  predictions = scaler.inverse_transform(predictions)\n",
    "  predictions = predictions.tolist()\n",
    "  predictions = pd.DataFrame(predictions)\n",
    "  predictions = predictions.rename(columns={0: \"aqi\", 1: \"pm10\", 2: \"pm25\", \n",
    "                                          3: \"o3\", 4: \"so2\", \n",
    "                                          5: \"no2\", 6: \"co\"})\n",
    "\n",
    "  # convert to ISPU\n",
    "  predictions = convert_ISPU(predictions)\n",
    "\n",
    "  # merge data a and predictions\n",
    "  frame = [a, predictions]\n",
    "  df_merge = pd.concat(frame)\n",
    "  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')\n",
    "  df_merge = df_merge.sort_index(ascending=False)\n",
    "\n",
    "  # reset index and format datetime to obj\n",
    "  df_merge = df_merge.reset_index()\n",
    "  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  # data prediction for return\n",
    "  result_pred = df_merge[:3]\n",
    "  result_pred = result_pred.sort_index(ascending=False)\n",
    "  result_pred = result_pred.values.tolist()\n",
    "  result_pred = list_to_dict(result_pred)\n",
    "\n",
    "  # data history for return\n",
    "  result_hist = df_merge[4:7]\n",
    "  result_hist = result_hist.values.tolist()\n",
    "  result_hist = list_to_dict(result_hist)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # merge result_pred and result_hist to dict data\n",
    "  data = ({\n",
    "      \"data\": ({\n",
    "          \"forecast\": result_pred,\n",
    "          \"history\": result_hist\n",
    "      })\n",
    "  })\n",
    "\n",
    "   \n",
    "  return data\n",
    "\n",
    "# /current?key=8ad9eca88a2e4330a022ad816a7d9886\n",
    "@app.route(\"/current\")\n",
    "def current():\n",
    "  weatherbit_key = request.args.get('key', default = \"8ad9eca88a2e4330a022ad816a7d9886\", type = str)\n",
    "\n",
    "  data = current_aqi_prov(weatherbit_key)\n",
    "  data = list_to_dict_prov(data)\n",
    "  \n",
    "  data = ({\n",
    "      \"data\": ({\n",
    "          \"current\": data\n",
    "      })\n",
    "  })\n",
    "  \n",
    "  return data\n",
    "\n",
    "# /w_by_city?city=Jakarta&key=a98a87d5120e4a86ba63d4c67fe8e81f\n",
    "@app.route(\"/w_by_city\")\n",
    "def w_by_city():\n",
    "  kota = request.args.get('city', default = \"Jakarta\", type = str)\n",
    "  weatherbit_key = request.args.get('key', default = \"a98a87d5120e4a86ba63d4c67fe8e81f\", type = str)\n",
    "\n",
    "  # collect data\n",
    "  a = weather_by_city(kota, weatherbit_key)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # scaling and reshape\n",
    "  scaler = MinMaxScaler()\n",
    "  data = scaler.fit_transform(a)\n",
    "  data = data.reshape(1,3,3)\n",
    "\n",
    "  # predictions and dataframing\n",
    "  predictions = model1.predict(data)\n",
    "  predictions = predictions.reshape(3,3)\n",
    "  predictions = scaler.inverse_transform(predictions)\n",
    "  predictions = predictions.tolist()\n",
    "  predictions = pd.DataFrame(predictions)\n",
    "  predictions = predictions.rename(columns={0: \"rh\", 1: \"wind_spd\", 2: \"temp\"})\n",
    "\n",
    "  # merge data a and predictions\n",
    "  frame = [a, predictions]\n",
    "  df_merge = pd.concat(frame)\n",
    "  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')\n",
    "  df_merge = df_merge.sort_index(ascending=False)\n",
    "\n",
    "  # reset index and format datetime to obj\n",
    "  df_merge = df_merge.reset_index()\n",
    "  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  # data prediction for return\n",
    "  result_pred = df_merge[:3]\n",
    "  result_pred = result_pred.sort_index(ascending=False)\n",
    "  result_pred = result_pred.values.tolist()\n",
    "  result_pred = weather_list_to_dict(result_pred)\n",
    "\n",
    "  # data history for return\n",
    "  result_hist = df_merge[3:6]\n",
    "  result_hist = result_hist.values.tolist()\n",
    "  result_hist = weather_list_to_dict(result_hist)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # merge result_pred and result_hist to dict data\n",
    "  data = ({\n",
    "      \"data\": ({\n",
    "          \"forecast\": result_pred,\n",
    "          \"history\": result_hist\n",
    "      })\n",
    "  })\n",
    "  return data\n",
    "   \n",
    "  \n",
    "\n",
    "# /w_by_location?lat=35&lon=-78&key=8ad9eca88a2e4330a022ad816a7d9886\n",
    "@app.route(\"/w_by_location\")\n",
    "def w_by_location():\n",
    "  lat = request.args.get('lat', default = 35, type = float)\n",
    "  lon = request.args.get('lon', default = -78, type = float)\n",
    "  weatherbit_key = request.args.get('key', default = \"8ad9eca88a2e4330a022ad816a7d9886\", type = str)\n",
    "\n",
    "  # collect data\n",
    "  a = weather_by_location(lat, lon, weatherbit_key)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # scaling and reshape\n",
    "  scaler = MinMaxScaler()\n",
    "  data = scaler.fit_transform(a)\n",
    "  data = data.reshape(1,3,3)\n",
    "\n",
    "  # predictions and dataframing\n",
    "  predictions = model1.predict(data)\n",
    "  predictions = predictions.reshape(3,3)\n",
    "  predictions = scaler.inverse_transform(predictions)\n",
    "  predictions = predictions.tolist()\n",
    "  predictions = pd.DataFrame(predictions)\n",
    "  predictions = predictions.rename(columns={0: \"rh\", 1: \"wind_spd\", 2: \"temp\"})\n",
    "\n",
    "  # merge data a and predictions\n",
    "  frame = [a, predictions]\n",
    "  df_merge = pd.concat(frame)\n",
    "  df_merge.index = pd.date_range(df_merge.index[0], periods=len(df_merge), freq='1h')\n",
    "  df_merge = df_merge.sort_index(ascending=False)\n",
    "\n",
    "  # reset index and format datetime to obj\n",
    "  df_merge = df_merge.reset_index()\n",
    "  df_merge['index'] = df_merge['index'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "  # data prediction for return\n",
    "  result_pred = df_merge[:3]\n",
    "  result_pred = result_pred.sort_index(ascending=False)\n",
    "  result_pred = result_pred.values.tolist()\n",
    "  result_pred = weather_list_to_dict(result_pred)\n",
    "\n",
    "  # data history for return\n",
    "  result_hist = df_merge[3:6]\n",
    "  result_hist = result_hist.values.tolist()\n",
    "  result_hist = weather_list_to_dict(result_hist)\n",
    "  a = a.sort_index()\n",
    "\n",
    "  # merge result_pred and result_hist to dict data\n",
    "  data = ({\n",
    "      \"data\": ({\n",
    "          \"forecast\": result_pred,\n",
    "          \"history\": result_hist\n",
    "      })\n",
    "  })\n",
    "  return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

import numpy as np


# format List in list to dict with key
def list_to_dict(lst):
  # format list value to int
  x = lst
  data = []

  for i in range(len(x)):
    item_x = x[i]
    for item in item_x:
      z = {"datetime": item_x[0],
           "aqi": item_x[1],
           "pm10": item_x[2],
           "pm25": item_x[3],
           "o3": item_x[4],
           "so2": item_x[5],
           "no2": item_x[6],
           "co": item_x[7]}
    
      if z not in data:
        data.append(z)
        
  return data

# format list to dict for aqi 34 province
def list_to_dict_prov(lst):
  x = lst
  data = []

  for i in range(len(x)):
    item_x = x[i]
    for item in item_x:
      z = {"city": item_x[0],
           "lat": item_x[1],
           "lon": item_x[2],
           "aqi": item_x[3],
           "pm10": item_x[4],
           "pm25": item_x[5],
           "o3": item_x[6],
           "so2": item_x[7],
           "no2": item_x[8],
           "co": item_x[9]}
    
      if z not in data:
        data.append(z)
     
  return data

def weather_list_to_dict(lst):
  # format list value to int
  x = lst
  data = []

  for i in range(len(x)):
    item_x = x[i]
    for item in item_x:
      z = {"datetime" : item_x[0],
          "rh": item_x[1],
          "wind_spd": item_x[2],
          "temp": item_x[3],}
    
      if z not in data:
        data.append(z)
        
  return data

web: gunicorn app:app
# Endpoint

## Current

- URL
  - /current/?key="WEATHERBIT_KEY"
- Method
  - GET
- Parameters
  - key = weatherbit key
- Respone

  ```json
  {
  "data": {
      "current": [
          {
              "aqi": 259,
              "city": "Serang",
              "co": 1842.5,
              "lat": -6.12,
              "lon": 106.15,
              "no2": 19.5354,
              "o3": 85.1154,
              "pm10": 154.762,
              "pm25": 137.529,
              "so2": 5.00679
          },
          {
              "aqi": 162,
              "city": "Bandung",
              "co": 1348.5,
              "lat": -6.92,
              "lon": 107.61,
              "no2": 26.39,
              "o3": 92.9832,
              "pm10": 74.014,
              "pm25": 64.2349,
              "so2": 15.0204
          },
          ...
      ]
    }
  }
  ```

## History & Prediction air quality by latitude longitude

- URL
  - /by_location?lat="LATITUDE"&lon="LONGITUDE"&key="WEATHERBIT_KEY"
- Method
  - GET
- Parameter
  - lat = latitude
  - long = longitude
  - key = weatherbit key
- Response
  ```json
  {
    "data": {
      "forecast": [
        {
          "aqi": 35.63230514526367,
          "co": 250.86363220214844,
          "datetime": "2022-06-10 15:00:00",
          "no2": 1.7819881439208984,
          "o3": 80.52020263671875,
          "pm10": 6.425139904022217,
          "pm25": 4.549275875091553,
          "so2": 0.6959050893783569
        },
        {
          "aqi": 35.75181579589844,
          "co": 253.9100799560547,
          "datetime": "2022-06-10 14:00:00",
          "no2": 1.8818491697311401,
          "o3": 80.3956527709961,
          "pm10": 6.713098049163818,
          "pm25": 4.722179889678955,
          "so2": 0.7107279896736145
        },
        {
          "aqi": 36.89277648925781,
          "co": 260.11260986328125,
          "datetime": "2022-06-10 13:00:00",
          "no2": 1.966313123703003,
          "o3": 79.4944076538086,
          "pm10": 6.969505310058594,
          "pm25": 4.887365341186523,
          "so2": 0.7187684774398804
        }
      ],
      "history": [
        {
          "aqi": 36.0,
          "co": 256.67,
          "datetime": "2022-06-10 12:00:00",
          "no2": 2.8,
          "o3": 78.0,
          "pm10": 6.49,
          "pm25": 4.69,
          "so2": 0.58
        },
        {
          "aqi": 34.0,
          "co": 245.89,
          "datetime": "2022-06-10 11:00:00",
          "no2": 2.39,
          "o3": 74.0,
          "pm10": 5.48,
          "pm25": 4.04,
          "so2": 0.79
        },
        {
          "aqi": 34.0,
          "co": 235.1,
          "datetime": "2022-06-10 10:00:00",
          "no2": 1.99,
          "o3": 72.67,
          "pm10": 4.47,
          "pm25": 3.39,
          "so2": 0.99
        },
        {
          "aqi": 32.0,
          "co": 224.32,
          "datetime": "2022-06-10 09:00:00",
          "no2": 1.58,
          "o3": 70.0,
          "pm10": 3.46,
          "pm25": 2.74,
          "so2": 1.2
        },
        {
          "aqi": 32.0,
          "co": 225.83,
          "datetime": "2022-06-10 08:00:00",
          "no2": 1.46,
          "o3": 70.0,
          "pm10": 3.66,
          "pm25": 2.91,
          "so2": 1.19
        },
        {
          "aqi": 29.0,
          "co": 227.35,
          "datetime": "2022-06-10 07:00:00",
          "no2": 1.34,
          "o3": 63.28,
          "pm10": 3.86,
          "pm25": 3.08,
          "so2": 1.18
        }
      ]
    }
  }
  ```

## History & Prediction air quality by city

- URL
  - /by_city?city="CITY_NAME"&key="WEATHERBIT_KEY"
- Method
  - GET
- Parameter
  - city = city name
  - key = weatherbit key
- Response

```json
{
  "data": {
    "forecast": [
      {
        "aqi": 35.63230514526367,
        "co": 250.86363220214844,
        "datetime": "2022-06-10 15:00:00",
        "no2": 1.7819881439208984,
        "o3": 80.52020263671875,
        "pm10": 6.425139904022217,
        "pm25": 4.549275875091553,
        "so2": 0.6959050893783569
      },
      {
        "aqi": 35.75181579589844,
        "co": 253.9100799560547,
        "datetime": "2022-06-10 14:00:00",
        "no2": 1.8818491697311401,
        "o3": 80.3956527709961,
        "pm10": 6.713098049163818,
        "pm25": 4.722179889678955,
        "so2": 0.7107279896736145
      },
      {
        "aqi": 36.89277648925781,
        "co": 260.11260986328125,
        "datetime": "2022-06-10 13:00:00",
        "no2": 1.966313123703003,
        "o3": 79.4944076538086,
        "pm10": 6.969505310058594,
        "pm25": 4.887365341186523,
        "so2": 0.7187684774398804
      }
    ],
    "history": [
      {
        "aqi": 36.0,
        "co": 256.67,
        "datetime": "2022-06-10 12:00:00",
        "no2": 2.8,
        "o3": 78.0,
        "pm10": 6.49,
        "pm25": 4.69,
        "so2": 0.58
      },
      {
        "aqi": 34.0,
        "co": 245.89,
        "datetime": "2022-06-10 11:00:00",
        "no2": 2.39,
        "o3": 74.0,
        "pm10": 5.48,
        "pm25": 4.04,
        "so2": 0.79
      },
      {
        "aqi": 34.0,
        "co": 235.1,
        "datetime": "2022-06-10 10:00:00",
        "no2": 1.99,
        "o3": 72.67,
        "pm10": 4.47,
        "pm25": 3.39,
        "so2": 0.99
      },
      {
        "aqi": 32.0,
        "co": 224.32,
        "datetime": "2022-06-10 09:00:00",
        "no2": 1.58,
        "o3": 70.0,
        "pm10": 3.46,
        "pm25": 2.74,
        "so2": 1.2
      },
      {
        "aqi": 32.0,
        "co": 225.83,
        "datetime": "2022-06-10 08:00:00",
        "no2": 1.46,
        "o3": 70.0,
        "pm10": 3.66,
        "pm25": 2.91,
        "so2": 1.19
      },
      {
        "aqi": 29.0,
        "co": 227.35,
        "datetime": "2022-06-10 07:00:00",
        "no2": 1.34,
        "o3": 63.28,
        "pm10": 3.86,
        "pm25": 3.08,
        "so2": 1.18
      }
    ]
  }
}
```

## History & Prediction weather by lotitude & longitude

- URL
  - /w_by_location?lat="LATITUDE"&lon="LONGITUDE"&key="WEATHERBIT_KEY"
- Method
  - GET
- Parameter
  - lat = latitude
  - long = longitude
  - key = weatherbit key
- Response

```json
{
  "data": {
    "forecast": [
      {
        "datetime": "2022-06-15 07:00:00",
        "rh": 88.6039810180664,
        "temp": 24.344493865966797,
        "wind_spd": 1.1674940586090088
      },
      {
        "datetime": "2022-06-15 08:00:00",
        "rh": 88.64962768554688,
        "temp": 24.27583122253418,
        "wind_spd": 1.1412063837051392
      },
      {
        "datetime": "2022-06-15 09:00:00",
        "rh": 88.66068267822266,
        "temp": 24.233928680419922,
        "wind_spd": 1.120360255241394
      }
    ],
    "history": [
      {
        "datetime": "2022-06-15 06:00:00",
        "rh": 88.0,
        "temp": 24.0,
        "wind_spd": 1.0
      },
      {
        "datetime": "2022-06-15 05:00:00",
        "rh": 88.0,
        "temp": 25.0,
        "wind_spd": 1.0
      },
      {
        "datetime": "2022-06-15 04:00:00",
        "rh": 88.0,
        "temp": 26.0,
        "wind_spd": 1.0
      }
    ]
  }
}
```

## History & Prediction weather by city

- URL
  - /w_by_city?city="CITY_NAME"&key="WEATHERBIT_KEY"
- Method
  - GET
- Parameter
  - city = city name
  - key = weatherbit key
- Response

```json
{
  "data": {
    "forecast": [
      {
        "datetime": "2022-06-15 07:00:00",
        "rh": 88.6039810180664,
        "temp": 24.344493865966797,
        "wind_spd": 1.1674940586090088
      },
      {
        "datetime": "2022-06-15 08:00:00",
        "rh": 88.64962768554688,
        "temp": 24.27583122253418,
        "wind_spd": 1.1412063837051392
      },
      {
        "datetime": "2022-06-15 09:00:00",
        "rh": 88.66068267822266,
        "temp": 24.233928680419922,
        "wind_spd": 1.120360255241394
      }
    ],
    "history": [
      {
        "datetime": "2022-06-15 06:00:00",
        "rh": 88.0,
        "temp": 24.0,
        "wind_spd": 1.0
      },
      {
        "datetime": "2022-06-15 05:00:00",
        "rh": 88.0,
        "temp": 25.0,
        "wind_spd": 1.0
      },
      {
        "datetime": "2022-06-15 04:00:00",
        "rh": 88.0,
        "temp": 26.0,
        "wind_spd": 1.0
      }
    ]
  }
}
```

Flask==1.1.2
gunicorn==19.9.0
itsdangerous==1.1.0
Jinja2==2.10.1
MarkupSafe==1.1.1
Werkzeug==2.0.3
numpy>=1.20.3
scipy>=0.15.1
scikit-learn>=0.18
pandas==1.3.4
glom==22.1.0
tensorflow-cpu==2.9.1

python-3.8.13
README.md
plot.png
Model/lstm_6_3_e50/plot.png
aqi_34prov1.zip
Dataset/aqi_34prov1.zip
flask.ipynb
__pycache__
.ipynb_checkpoints
